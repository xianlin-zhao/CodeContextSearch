import os
#os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HF_ENDPOINT'] = 'https://huggingface.co'
import json
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re
from tqdm import tqdm
import torch
import torch.nn.functional as F
from search_models.unixcoder import UniXcoder
from utils.query_refine import refine_query

# PROJECT_PATH = "Internet/boto"
# PROJECT_PATH = "System/mrjob"
PROJECT_PATH ="Database/alembic"

# FEATURE_CSV = "/data/data_public/riverbag/testRepoSummaryOut/mrjob/1:7.6/features.csv" 
# METHODS_CSV = "/data/data_public/riverbag/testRepoSummaryOut/mrjob/1:7.6/methods.csv" 
# FILTERED_PATH = "/data/data_public/riverbag/testRepoSummaryOut/mrjob/1:7.6/filtered.jsonl" 
# refined_queries_cache_path = '/data/data_public/riverbag/testRepoSummaryOut/mrjob/1:3/refined_queries.json'

# FEATURE_CSV = "/data/data_public/riverbag/testRepoSummaryOut/boto/1:8/features.csv" 
# METHODS_CSV = "/data/data_public/riverbag/testRepoSummaryOut/boto/1:8/methods.csv" 
# FILTERED_PATH = "/data/data_public/riverbag/testRepoSummaryOut/boto/1:8/filtered.jsonl" 
# refined_queries_cache_path = '/data/data_public/riverbag/testRepoSummaryOut/boto/1:5/refined_queries.json'

FEATURE_CSV = "/data/data_public/riverbag/testRepoSummaryOut/alembic/1:5/features.csv" 
METHODS_CSV = "/data/data_public/riverbag/testRepoSummaryOut/alembic/1:5/methods.csv" 
FILTERED_PATH = "/data/data_public/riverbag/testRepoSummaryOut/alembic/1:5/filtered.jsonl" 
refined_queries_cache_path = '/data/data_public/riverbag/testRepoSummaryOut/alembic/1:3/refined_queries.json' 
# DevEval数据集case的路径（json，不是数据集项目本身）
DATA_JSONL = "/data/lowcode_public/DevEval/data_have_dependency_cross_file.jsonl"

# 是否需要把method名称规范化，例如得到的csv中是mrjob.mrjob.xx，将其规范化为mrjob.xx，以便进行测评
NEED_METHOD_NAME_NORM = True
USE_REFINED_QUERY = True

# Recall parameters
# RECALL_CLUSTER_K = 5  # Use top 5 clusters for recall
CLUSTER_KS = [1, 3, 5]
SIG_KS = [5, 10, 15]

def load_unixcoder_model(model_path_or_name=None, device=None):
    """
    Attempt to load UniXcoder model and move it to a device.
    Returns (model, device).
    """
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    try:
        model = UniXcoder(model_path_or_name if model_path_or_name else "microsoft/unixcoder-base")
        model.to(device)
        model.eval()
        return model, device
    except Exception:
        raise ImportError("Unable to import UniXcoder. Ensure UniXcoder is installed / in PYTHONPATH and adjust load_unixcoder_model().")

def encode_corpus_with_unixcoder(model, device, texts, batch_size=32, max_length=512):
    """
    Encode a list of texts (function code strings) into normalized embeddings using UniXcoder.
    We tokenize and encode one example at a time (model.tokenize([text])) so source_ids is a rectangular tensor.
    Returns a torch.FloatTensor of shape (N, D) on CPU (normalized).
    """
    all_embs = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        for func in batch:
            # tokenize one example as in official snippet to ensure rectangular tensor shape
            tokens_ids = model.tokenize([func], max_length=max_length, mode="<encoder-only>")
            source_ids = torch.tensor(tokens_ids).to(device)  # shape (1, L)
            with torch.no_grad():
                _, func_embedding = model(source_ids)
                normed = F.normalize(func_embedding, p=2, dim=1)  # shape (1, D)
                all_embs.append(normed.cpu())
    # concat
    if len(all_embs) == 0:
        return torch.empty((0,0))
    code_embs = torch.cat(all_embs, dim=0)
    return code_embs  # on CPU

def encode_nl_with_unixcoder(model, device, text, max_length=512):
    # tokenize one NL example and encode
    tokens_ids = model.tokenize([text], max_length=max_length, mode="<encoder-only>")
    source_ids = torch.tensor(tokens_ids).to(device)
    with torch.no_grad():
        _, nl_embedding = model(source_ids)
        nl_embedding = F.normalize(nl_embedding, p=2, dim=1)  # shape (1, dim)
    return nl_embedding.cpu()

def analyze_project(project_path):
    # Step 1: Filter by project_path
    print("Filtering data...")
    with open(DATA_JSONL, 'r') as infile, open(FILTERED_PATH, 'w') as outfile:
        for line in infile:
            data = json.loads(line.strip())
            if data.get('project_path') == project_path:
                outfile.write(line)
    
    # Step 2: Load Features and Clusters
    print("Loading features...")
    df = pd.read_csv(
        FEATURE_CSV,
        dtype=str,
        keep_default_na=False,
        quoting=0,
        engine="python",
        on_bad_lines="skip"
    )
    clusters = df.groupby('id')['desc'].first().reset_index()
    
    # 提取clusters中所有的method_name
    method_names = df['method_name'].str.split('(').str[0].unique().tolist()

    if NEED_METHOD_NAME_NORM:
        # 规范化 method_name：去掉参数，只保留第一个点后的部分，例如 mrjob.hadoop.main -> hadoop.main
        base_names = df['method_name'].astype(str).str.split('(').str[0]
        df['method_name_norm'] = base_names.str.split('.', n=1).str[1].fillna(base_names)
        method_names = df['method_name_norm'].unique().tolist()
    print(f"Loaded {len(method_names)} unique method names from features.")
    print(method_names[:10])

    print("Encoding clusters...")
    # # model = SentenceTransformer('all-mpnet-base-v2')
    # model = SentenceTransformer('all-MiniLM-L6-v2')
    model_path = "/data/data_public/riverbag/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf"

    if os.path.exists(model_path):
        print(f"找到本地模型: {model_path}")
        model = SentenceTransformer(model_path)
    else:
        print(f"未找到本地模型，尝试下载...")
        # 如果本地没有，再尝试从网络下载
        model = SentenceTransformer('all-MiniLM-L6-v2')
    cluster_embeddings = model.encode(clusters['desc'].tolist())

    # Step 3: Load Methods for UniXcoder
    print("Loading methods for UniXcoder...")
    methods_df = pd.read_csv(METHODS_CSV, dtype=str).fillna('')
    if 'method_signature' not in methods_df.columns or 'method_code' not in methods_df.columns:
        raise ValueError("methods.csv must contain 'method_signature' and 'method_code' columns")

    methods_corpus_strings = methods_df['method_signature'].tolist()
    method_codes = methods_df['method_code'].tolist()

    # Load UniXcoder model
    print("Loading UniXcoder model...")
    unix_model, device = load_unixcoder_model()

    # Encode all method codes with UniXcoder
    print("Encoding all method_code with UniXcoder (this may take a while)...")
    # This might be slow if we do it for all methods. 
    # But for accurate re-ranking we need embeddings for candidates.
    # However, since we are doing re-ranking after feature search, we might only need embeddings for recalled candidates.
    # But to map indices easily, let's pre-compute all or compute on the fly for candidates.
    # Pre-computing all is safer for index mapping consistency.
    # If the number of methods is huge, we might want to optimize. Assuming < 100k methods, it's doable.
    code_embs_all = encode_corpus_with_unixcoder(unix_model, device, method_codes, batch_size=32)
    # Move to GPU if possible for fast indexing? Or keep on CPU and move batch to GPU?
    # For simplicity, keep on CPU and move relevant parts to GPU during search or use CPU for dot product if small.
    # Actually, we will pick candidates, so we can index into code_embs_all.
    
    # Build Mapping: Feature Method Name -> Indices in methods_df
    print("Building mapping from Feature names to Method indices...")
    feature_name_to_indices = {}
    
    # Similar to feature_BM25Code.py logic
    raw_feature_names = df['method_name'].unique().tolist()
    
    for idx, sig in enumerate(methods_corpus_strings):
        for fname in raw_feature_names:
            if fname in sig:
                if fname not in feature_name_to_indices:
                    feature_name_to_indices[fname] = []
                feature_name_to_indices[fname].append(idx)
                
    print(f"Mapping built for {len(feature_name_to_indices)} feature names.")

    # Load or initialize the query cache
    if os.path.exists(refined_queries_cache_path):
        with open(refined_queries_cache_path, 'r') as f:
            refined_queries_cache = json.load(f)
    else:
        refined_queries_cache = {}
        with open(refined_queries_cache_path, 'w') as f:
            json.dump(refined_queries_cache, f, indent=2)

    # Helper functions
    def methods_from_top_k_clusters(similarities, k):
        idx = np.argsort(similarities)[-k:][::-1]
        ids = clusters.iloc[idx]["id"].tolist()
        methods = []
        for cid in ids:
            methods.extend(df[df["id"] == cid]["method_name"].tolist())
        return list(set(methods)) # Dedup
       

    def safe_div(a, b):
        return (a / b) if b != 0 else 0

    # Evaluation
    print("Starting Hybrid Search Evaluation (Feature + UniXcoder)...")
    with open(FILTERED_PATH, 'r') as f:
        lines = f.readlines()

    hybrid_records = []
    
    # Metrics containers
    metrics = {}
    for ck in CLUSTER_KS:
        metrics[ck] = {}
        for sk in SIG_KS:
            metrics[ck][sk] = {"match": 0, "pred": 0}
            
    top_gt = 0
    example_counter = 0

    for line in tqdm(lines):
        example_counter += 1
        data = json.loads(line.strip())
        deps = []
        deps.extend(data['dependency']['intra_class'])
        deps.extend(data['dependency']['intra_file'])
        deps.extend(data['dependency']['cross_file'])
        
        # Filter deps by the normalized method names
        deps = [dep for dep in deps if dep in method_names]
        top_gt += len(deps)

        # Feature Search Embedding
        # Logic for query refinement
        original_query = data['requirement']['Functionality'] + ' ' + data['requirement']['Arguments']
        
        if USE_REFINED_QUERY:
            if original_query in refined_queries_cache:
                query = refined_queries_cache[original_query]
                # print("found in cache")
            else:
                modelname = "deepseek-v3"
                query = refine_query(original_query, modelname)
                refined_queries_cache[original_query] = query
                # Add and save immediately
                with open(refined_queries_cache_path, 'w') as f:
                    json.dump(refined_queries_cache, f, indent=2)
            # print("refined query: ", query)
        else:
            query = original_query
            # print("Using original query: ", query)

        # Encode query for Feature Search
        query_embedding = model.encode([query])
        similarities = cosine_similarity(query_embedding, cluster_embeddings)[0]
        
        # Encode query for UniXcoder
        nl_emb_unix = encode_nl_with_unixcoder(unix_model, device, query) # shape (1, D)
        nl_emb_unix = nl_emb_unix.to(device) # Move to device for dot product

        # Prepare record for this example
        record = {
            "example_id": example_counter,
            "query": query,
            "ground_truth": deps,
            "hybrid": {}
        }

        # Iterate over different Cluster Recall Ks
        for ck in CLUSTER_KS:
            # 1. Feature Search Recall (Top ck clusters)
            recalled_raw_names = methods_from_top_k_clusters(similarities, ck)
            
            # Map to indices
            candidate_indices = set()
            for rname in recalled_raw_names:
                if rname in feature_name_to_indices:
                    candidate_indices.update(feature_name_to_indices[rname])
            
            candidate_indices = list(candidate_indices)
            
            # 2. UniXcoder Re-ranking on Code
            final_methods = []
            if candidate_indices:
                # Get embeddings for candidates
                # code_embs_all is on CPU
                cand_embs = code_embs_all[candidate_indices].to(device) # Move only candidates to GPU
                
                # Compute similarity
                with torch.no_grad():
                     # (1, D) * (M, D)^T = (1, M)
                    sims = torch.mm(nl_emb_unix, cand_embs.t()).squeeze(0) # shape (M,)
                
                # Sort indices by score desc
                sorted_indices_local = torch.argsort(sims, descending=True).cpu().numpy()
                
                # Map back to global indices and then to strings
                scored_candidates = []
                for local_idx in sorted_indices_local:
                    global_idx = candidate_indices[local_idx]
                    score = sims[local_idx].item()
                    scored_candidates.append((score, methods_corpus_strings[global_idx]))
                
                # Extract method signatures
                final_methods = [x[1] for x in scored_candidates]
            
            # 3. Calculate metrics for different Signature Top-Ks (SIG_KS)
            record["hybrid"][f"recall_top{ck}_clusters"] = {}
            
            for sk in SIG_KS:
                mk = final_methods[:sk]
                
                num_match = sum(1 for dep in deps if any(dep in m for m in mk))
                num_pred = len(mk)
                
                metrics[ck][sk]["pred"] += num_pred
                metrics[ck][sk]["match"] += num_match
                
                # Per-example metrics
                num_gt_ex = len(deps)
                p = safe_div(num_match, num_pred)
                r = safe_div(num_match, num_gt_ex)
                f1 = safe_div(2 * p * r, p + r)
                
                record["hybrid"][f"recall_top{ck}_clusters"][f"rank_top{sk}"] = {
                    "metrics": {"P": p, "R": r, "F1": f1, "pred": num_pred, "match": num_match, "gt": num_gt_ex},
                    "predictions": [{"method": m, "match": any(dep in m for dep in deps)} for m in mk]
                }
        
        hybrid_records.append(record)

    # Output results
    out_dir = os.path.dirname(FILTERED_PATH)
    hybrid_path = os.path.join(out_dir, "diagnostic_hybrid_unixcoder.jsonl")
    with open(hybrid_path, "w", encoding="utf-8") as fo:
        for rec in hybrid_records:
            fo.write(json.dumps(rec, ensure_ascii=False) + "\n")

    print("\nHybrid Search Results (Feature Recall + UniXcoder Code Re-rank):")
    print("Format: Recall Top-K Clusters -> Rank Top-K Results")
    print("="*60)
    
    for ck in CLUSTER_KS:
        print(f"--- Feature Search Recall: Top {ck} Clusters ---")
        for sk in SIG_KS:
            m = metrics[ck][sk]["match"]
            p = metrics[ck][sk]["pred"]
            
            precision = (safe_div(m, p)) * 100
            recall = (safe_div(m, top_gt)) * 100
            
            denom = safe_div(m, p) + safe_div(m, top_gt)
            f1 = (2 * safe_div(m, p) * safe_div(m, top_gt) / denom) * 100 if denom > 0 else 0
            
            print(f"  Rank Top {sk}:")
            print(f"    Match: {m}, Pred: {p}")
            print(f"    P={precision:.2f}%, R={recall:.2f}%, F1={f1:.2f}%")
        print("-" * 60)

    print(f"Hybrid analysis completed. Results saved to {hybrid_path}")

if __name__ == "__main__":
    analyze_project(PROJECT_PATH)
